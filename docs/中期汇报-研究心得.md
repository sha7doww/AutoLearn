# 研究心得

## 一、技术选型与架构设计的思考

项目启动初期，我们在技术选型上经历了较长时间的探索和反复。最初的设想是直接基于传统的协同过滤算法实现课程推荐，但在深入调研相关文献后发现，这种方法存在明显的冷启动问题和可解释性不足的缺陷。这促使我们重新审视问题的本质：学生需要的不仅是"推荐结果"，更需要理解"为什么要这样学"。

**成功经验**：在确定使用Agentic Search架构之前，我们花了大量时间阅读近两年的顶会论文（AAAI、EDM等），发现Agent技术在教育领域的应用还处于起步阶段，这给了我们创新的空间。通过对比MultiTutor、PlanGlow等现有工作，我们明确了自己的差异化方向：将知识追踪与Agent搜索深度结合。这个过程让我们深刻体会到，**充分的文献调研是创新的基础，而非时间浪费**。

**失败教训**：在后端框架选择上，我们最初计划使用Django，因为团队成员更熟悉。但在实际开发中发现Django的同步特性不适合Agent的异步推理流程，最终不得不切换到FastAPI。这次返工浪费了约一周时间，教训是**技术选型不能只考虑熟悉度，必须匹配实际需求**。如果当初做技术选型时先做小规模的原型验证，就能避免这个问题。

## 二、从理论到实践的鸿沟

在阅读论文时，许多算法看起来优雅且高效，但实际实现时却遇到了大量意想不到的困难。

**知识追踪模型的数据困境**：IRT模型在论文中通常假设有大量的学生做题数据，但我们在实际操作中发现，收集真实的学生学习数据非常困难——既涉及隐私问题，又难以获得学校教务系统的支持。最初我们计划直接使用真实成绩数据，但在与辅导员沟通后发现流程复杂且审批周期长。

**解决方案**：我们转而采用"先用模拟数据验证算法，再逐步引入真实数据"的策略。设计了基于正态分布的成绩生成器，模拟不同能力水平的学生。虽然这降低了模型的实际效果，但至少保证了项目能够推进。这个经历让我们认识到，**学术研究和工程实践的侧重点不同：前者追求理论创新，后者需要在资源约束下寻找可行方案**。

**成功经验**：在遇到数据困境后，我们主动联系了几位学长学姐，邀请他们提供匿名化的成绩数据作为测试样本。虽然数据量不大（仅5-10人），但足以验证算法的可行性。这个过程让我们学会了**灵活调整研究方案，在理想与现实之间寻找平衡**。

## 三、系统集成中的"魔鬼细节"

前后端分离的架构看似清晰，但实际集成时遇到了许多意想不到的问题。

**跨域请求的坑**：前端Vue运行在localhost:8080，后端FastAPI运行在localhost:8000，初次联调时所有API请求都被浏览器拦截，报CORS错误。虽然通过添加中间件解决了，但这个小问题困扰了我们半天。

**异步调用的复杂性**：Agent系统涉及多个异步工具调用（查询Neo4j、调用LLM API等），如何协调这些异步操作、处理超时和错误，比预想的复杂得多。最初的实现经常出现"部分工具执行成功、部分失败"的不一致状态，导致返回结果不完整。

**失败教训**：我们在开发初期没有充分考虑错误处理和异常情况，导致系统在测试时频繁崩溃。后来不得不花时间重构，为每个API接口添加try-except、为Agent工具添加超时机制、为数据库操作添加重试逻辑。这个经历告诉我们，**"让代码跑起来"和"让代码稳定运行"是两回事，后者需要更多的工程积累**。

**成功经验**：在后期开发中，我们开始采用"测试驱动开发"的思路，先写测试用例再写实现代码。虽然初期进度变慢，但大幅减少了bug数量。这让我们认识到，**规范的开发流程在项目后期会带来巨大的回报**。

## 四、对"创新"的重新理解

项目初期，我们对"创新"的理解比较狭隘，认为必须提出全新的算法或理论才算创新。但在项目推进过程中，我们逐渐意识到创新有多种形式。

**应用创新的价值**：我们的核心创新点之一是将Agent技术应用到教育推荐领域。虽然Agent技术本身不是我们发明的，但将其与知识追踪结合、设计适合教育场景的工具集，这本身就是创新。导师的一句话让我们印象深刻："解决实际问题的创新，比纯理论创新更有价值。"

**工程创新的挑战**：在构建完整系统的过程中，我们面临的许多问题在论文中找不到答案——如何设计前端交互让学生愿意使用？如何平衡推荐准确性和响应速度？如何让Agent的推理过程对用户透明？这些问题的解决同样需要创造性思维。

**收获**：现在我们理解到，**创新不仅是提出新理论，也包括新应用、新组合、新实现**。本科生创新项目的价值在于培养创新思维，而非一定要发表顶会论文。

## 五、团队协作与个人成长

虽然项目还在进行中，但已经让我们在多方面获得了成长。

**技术能力的提升**：从项目启动到现在，我们学习了FastAPI、LangChain、Neo4j等多项新技术，对前后端分离架构、图数据库、向量检索等有了实践层面的理解。更重要的是，我们学会了**如何快速学习新技术**——阅读官方文档、查找示例代码、在遇到问题时搜索Stack Overflow，这些技能比具体的技术知识更有长期价值。

**问题解决能力的锻炼**：项目中遇到的许多问题没有标准答案，需要自己探索解决方案。例如，如何表示学生的知识状态？用向量、用图、还是用概率分布？每种方案都有优缺点，需要权衡。这种"在不确定中做决策"的能力，是课堂学习中很难获得的。

**学术视野的拓展**：为了完成项目，我们阅读了30余篇相关论文，涵盖知识追踪、推荐系统、Agent技术等多个领域。这让我们对AI在教育中的应用有了系统性的认识，也激发了我们对学术研究的兴趣。目前我们计划在项目结束后整理成论文投稿，这将是我们第一次尝试学术写作。

**时间管理的挑战**：平衡课程学习、项目开发、期末考试是一个持续的挑战。初期我们经常因为沉迷于某个技术细节而忽略了整体进度，后来学会了使用甘特图规划任务、设定每周的里程碑。这个过程让我们认识到，**自我管理能力是科研工作的基础**。

## 六、对后续工作的反思

通过中期的实践，我们也意识到项目还存在一些不足，需要在后续工作中改进。

**用户需求调研不足**：我们在设计系统时更多从技术角度出发，较少考虑学生的实际使用场景。例如，学生真的会主动使用导学系统吗？他们更关心课程难度还是就业前景？这些问题我们还没有充分调研。后续计划开展用户访谈，收集真实需求。

**评估方法的缺失**：我们还没有明确如何评估系统的效果。是看推荐准确率？还是看学生满意度？还是看实际的学习效果提升？这些指标的设计需要进一步思考。

**可持续性的担忧**：当前系统依赖于手工标注的课程数据和先修关系，这些数据需要定期更新。如果课程设置调整、教学大纲变化，如何保持系统的时效性？这是工程化应用需要考虑的长期问题。

## 七、总结与展望

回顾项目的中期进展，我们最大的收获不是掌握了某项技术，而是**建立了从问题到解决方案的完整思维链条**：发现问题 → 调研现状 → 提出方案 → 技术实现 → 测试验证 → 迭代优化。这个过程充满挑战，但也充满成就感。

项目让我们认识到，创新创业不是一蹴而就的，需要在理论与实践、理想与现实、创新与可行之间不断平衡。失败和挫折是常态，重要的是从中学习、持续改进。接下来的工作中，我们将继续完善核心功能，开展用户测试，并尝试将系统推广到实际应用中。

无论最终成果如何，这段经历已经让我们在技术能力、科研素养、问题解决能力等多方面获得了宝贵的成长，这将是我们本科阶段最重要的收获之一。
